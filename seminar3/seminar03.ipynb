{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/adasegroup/ML2024_seminars/blob/master/seminar3/seminar03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7TSOzPKRgtT"
   },
   "source": [
    "# Measure quality of a classification model\n",
    "\n",
    "This notebook explains how to measure quality of a classification machine learning model.\n",
    "We provide definitions for various quality measures and try to find out if they are suitable or not for a particular machine learning classification problem.\n",
    "\n",
    "The data is a subsample from the kaggle comptetion \"Give me some credit\"\n",
    "https://www.kaggle.com/c/GiveMeSomeCredit#description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cfdaacbc-23a3-423d-8d4d-120939ac7383",
    "colab": {},
    "colab_type": "code",
    "id": "h72h_c_GRgtW"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# data processing tools: pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visualization tools: matplotlib, seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning tools: various methods from scikit-learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "from sklearn.metrics import f1_score, accuracy_score, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6JGwTssRgtc"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3ab4c525-a5cb-4183-9468-c1dd005c4c78",
    "colab": {},
    "colab_type": "code",
    "id": "oCQ791asRgte"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "training_data = pd.read_csv('https://raw.githubusercontent.com/adasegroup/ML2024_seminars/master/seminar3/credit/training_data.csv')\n",
    "test_data = pd.read_csv('https://raw.githubusercontent.com/adasegroup/ML2024_seminars/master/seminar3/credit/test_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ka4pA7SYRgtj"
   },
   "source": [
    "See some technical info about data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4V3veR0Rgtk"
   },
   "outputs": [],
   "source": [
    "# print information about the data\n",
    "training_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-nRKynmNRgtp"
   },
   "source": [
    "Let's look at some general statistics of data:\n",
    "* **count** -- number of not `NaN` values;\n",
    "* **mean**, **std** -- mean and standard deviation;\n",
    "* other -- minimal, maximal values, quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25EOI00gRgtq"
   },
   "outputs": [],
   "source": [
    "training_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iemJpso3Rgtt"
   },
   "source": [
    "Choose randomly ten objects from dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcD9qhzVRgtu"
   },
   "outputs": [],
   "source": [
    "training_data.sample(10, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDpi4RNtRgtx"
   },
   "source": [
    "We see that there are `NaN`s in data. Let's calculate mean values of features on **training data** and fill them in instead of the missing values. We will do that both for **train** and **test**.\n",
    "\n",
    "There are several ways to fill in skipped data:\n",
    "* mean, median;\n",
    "* regression predictions;\n",
    "* in case of time series -- last known value,\n",
    "* linear interpolation, etc.\n",
    "\n",
    "If the number of skipped values is small, you can throw the corresponding objects away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IGLwilrmTS8"
   },
   "outputs": [],
   "source": [
    "training_data[\"SeriousDlqin2yrs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S1ukXYlRgtz"
   },
   "outputs": [],
   "source": [
    "# fill NA values with mean training values\n",
    "train_mean = training_data.mean()\n",
    "\n",
    "training_data.fillna(train_mean, inplace=True)\n",
    "test_data.fillna(train_mean, inplace=True)\n",
    "\n",
    "print(training_data.isnull().sum())\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzpECX19Rgt1"
   },
   "source": [
    "Compare train and test distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhlyXAR_Rgt2"
   },
   "outputs": [],
   "source": [
    "axes = training_data.hist(figsize=(16, 9), bins=25, alpha=0.75) # that will plot training data histograms\n",
    "\n",
    "for plot in axes.flat: # that will draw test data on top of training histograms\n",
    "    column = plot.title.get_text()\n",
    "    if column:\n",
    "        test_data[column].hist(ax=plot, bins=25, alpha=0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_5xrhG2bRgt4"
   },
   "source": [
    "Pay attention to **SeriousDlqin2yrs** -- 90 days past due delinquency or worse in the last 2 years. We see that most of the borrowers pay in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbwfKx8ARgt4"
   },
   "outputs": [],
   "source": [
    "# The data set is imbalanced: typically people return credits\n",
    "training_data[\"SeriousDlqin2yrs\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWdP1Z2gRgt8"
   },
   "source": [
    "# Classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3M-AubqTRgt9"
   },
   "source": [
    "First of all, load data for learning as pairs $(X, y)$, where $X = (x_i)_{i=1}^n$ -- input features,\n",
    "and $y=(y_i)_{i=1}^n$ corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hl3hqXb8Rgt-"
   },
   "outputs": [],
   "source": [
    "training_X = training_data.drop(\"SeriousDlqin2yrs\", axis=1)\n",
    "training_y = training_data[\"SeriousDlqin2yrs\"]\n",
    "\n",
    "test_X = test_data.drop(\"SeriousDlqin2yrs\", axis=1)\n",
    "test_y = test_data[\"SeriousDlqin2yrs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kV1O9ZZZRguA"
   },
   "source": [
    "Construct calssification algorithms and train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTE1xxfzRguB"
   },
   "outputs": [],
   "source": [
    "# Construct Decision Tree model\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(max_depth = 5)\n",
    "decision_tree.fit(training_X, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz\n",
    "from graphviz import Source\n",
    "from sklearn import tree\n",
    "Source(tree.export_graphviz(decision_tree, out_file=None, feature_names=training_X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5XuE8LCRguD"
   },
   "outputs": [],
   "source": [
    "# Construct k Nearest Neighbors model\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(training_X, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSFOn2uFRguF"
   },
   "outputs": [],
   "source": [
    "print(\"Training accuracy:\")\n",
    "print(\"\\tDT accuracy:\\t%.2f%%\" % (100 * decision_tree.score(training_X, training_y)))\n",
    "print(\"\\tkNN accuracy:\\t%.2f%%\" % (100 * knn.score(training_X, training_y)))\n",
    "print(\"\\tNumber of '0' labels:\\t%.2f%%\" % (100 - 100 * np.mean(training_y)))\n",
    "print()\n",
    "\n",
    "print(\"Test accuracy:\")\n",
    "print(\"\\tDT accuarcy:\\t%.2f%%\" % (100 * decision_tree.score(test_X, test_y)))\n",
    "print(\"\\tkNN accuarcy:\\t%.2f%%\" % (100 * knn.score(test_X, test_y)))\n",
    "print(\"\\tNumber of '0' labels:\\t%.2f%%\" % (100 - 100 * np.mean(test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZzN4WBoRguH"
   },
   "outputs": [],
   "source": [
    "test_predictions_dt = decision_tree.predict(test_X)\n",
    "test_probabilities_dt = decision_tree.predict_proba(test_X)[:, 1]\n",
    "\n",
    "training_predictions_dt = decision_tree.predict(training_X)\n",
    "training_probabilities_dt = decision_tree.predict_proba(training_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPCXSNG9RguI"
   },
   "outputs": [],
   "source": [
    "test_predictions_knn = knn.predict(test_X)\n",
    "test_probabilities_knn = knn.predict_proba(test_X)[:, 1]\n",
    "\n",
    "training_predictions_knn = knn.predict(training_X)\n",
    "training_probabilities_knn = knn.predict_proba(training_X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "26dd2732-b34f-4177-8786-8794537494e1",
    "colab_type": "text",
    "id": "3IstWq8gRguL"
   },
   "source": [
    "# Classification quality measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3dScoO3hRguL"
   },
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Confusion matrix is table layout that allows visualization of the performance of an algorithm. Rows of this matrix correspond to actual classes of the test set, columns correspond to predicted labels. There are 4 types of elements if predictions are given:\n",
    "* True Positive\n",
    "* False Negative\n",
    "* False Positive\n",
    "* True Negative\n",
    "\n",
    "| Variable | Predicted True | Predicted False |\n",
    "| ------------- |-------------|-----|\n",
    "| Actual True  | TP | FN | \n",
    "| Actual False | FP | TN |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzywp8CWRguM"
   },
   "outputs": [],
   "source": [
    "confusion_dt = pd.DataFrame(confusion_matrix(test_y, test_predictions_dt))\n",
    "\n",
    "confusion_knn = pd.DataFrame(confusion_matrix(test_y, test_predictions_knn))\n",
    "\n",
    "print('Confusion for Decision Tree:')\n",
    "print(confusion_dt)\n",
    "print('Confusion for kNN:')\n",
    "print(confusion_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRDQ-Ad1RguN"
   },
   "source": [
    "If we want to compare metrics on different data, we can use instead True Positive Rate and False Positive Rate:\n",
    "* False Positive Rate is $\\frac{FP}{FP + TN}$\n",
    "* True  Positive Rate is $\\frac{TP}{TP + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "On9BbPlLRguO"
   },
   "source": [
    "## ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cxiJFHaRguO"
   },
   "source": [
    "ROC stands for *Receiver Operating Characteristic*. This curve shows True Positive Rate (**TPR**) against False Positive Rate (**FPR**) as classifier's discrimination threshold is varied\n",
    "\n",
    "Remember that classifiers are usually constructed based on some function\n",
    "$f(x) \\in [0, 1]$ and threshold $\\tau$:\n",
    "$$ \\text{Classifier}\\bigl(\\text{object}\\bigr)\n",
    "    = \\begin{cases}\n",
    "    1 & \\text{if}\\, f(\\text{object}) \\geq \\tau\\,,\\\\\n",
    "    0 & \\text{else}\\,.\n",
    "    \\end{cases}\n",
    "$$\n",
    "    \n",
    "**roc_curve** function from *scikit-learn* allows to easily obtain ROC curve points and **threshold** values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J0BwU2f9sSVa"
   },
   "source": [
    "Detailed description of ROC-AUC by Alexander Dyakonov (in Russian)\n",
    "https://dyakonov.org/2017/07/28/auc-roc-площадь-под-кривой-ошибок/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ZS_9IRTRguO"
   },
   "outputs": [],
   "source": [
    "false_positive_rates_dt, true_positive_rates_dt, threshold_dt = roc_curve(test_y, test_probabilities_dt)\n",
    "\n",
    "false_positive_rates_knn, true_positive_rates_knn, threshold_knn = roc_curve(test_y, test_probabilities_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvDKLoNuRguP"
   },
   "outputs": [],
   "source": [
    "# create plot\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "\n",
    "# specify parameters for the first curve\n",
    "plot_1 = fig.add_subplot(121,\n",
    "                       xlabel=\"FPR\", xlim=(-.01, 1.01),\n",
    "                       ylabel=\"TPR\", ylim=(-.01, 1.01), title = 'Decision Tree')\n",
    "\n",
    "# draw the first curve\n",
    "plot_1.plot(false_positive_rates_dt, true_positive_rates_dt,\n",
    "          color='darkorange', lw=2, label = 'ROC-curve on test')\n",
    "plot_1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle=':')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# specify parameters for the second curve\n",
    "plot_2 = fig.add_subplot(122,\n",
    "                       xlabel=\"FPR\", xlim=(-.01, 1.01),\n",
    "                       ylabel=\"TPR\", ylim=(-.01, 1.01), title = 'k Nearest Neighbors')\n",
    "\n",
    "# draw the second curve\n",
    "plot_2.plot(false_positive_rates_knn, true_positive_rates_knn,\n",
    "          color='darkorange', lw=2, label = 'ROC-curve on test')\n",
    "plot_2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle=':')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "abo7ybOJRguR"
   },
   "source": [
    "The closer **ROC** curve to the **upper left** corner, the better classification is.\n",
    "\n",
    "Despite being a good visual representation we usually need a number to make conclusions about calssification quality. In case of ROC curve this number is Area Under the Curve (**ROC-AUC**). \n",
    "\n",
    "*scikit-learn* has a special function **auc(...)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ahg07oWIRguS"
   },
   "outputs": [],
   "source": [
    "roc_auc_dt = auc(false_positive_rates_dt, true_positive_rates_dt)\n",
    "roc_auc_knn = auc(false_positive_rates_knn, true_positive_rates_knn)\n",
    "\n",
    "print(\"DT ROC-AUC on test data:\", roc_auc_dt) \n",
    "print(\"kNN ROC-AUC on test data:\", roc_auc_knn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUDXlgKgRguU"
   },
   "source": [
    "For the training set ROC curve and ROC-AUC look much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9tTlhOJBRguV"
   },
   "outputs": [],
   "source": [
    "training_false_positive_rates_dt, training_true_positive_rates_dt, _ = roc_curve(training_y, training_probabilities_dt)\n",
    "training_false_positive_rates_knn, training_true_positive_rates_knn, _ = roc_curve(training_y, training_probabilities_knn)\n",
    "\n",
    "training_roc_auc_dt = auc(training_false_positive_rates_dt, training_true_positive_rates_dt)\n",
    "training_roc_auc_knn = auc(training_false_positive_rates_knn, training_true_positive_rates_knn)\n",
    "\n",
    "print(\"DT ROC-AUC on training data:\", training_roc_auc_dt) \n",
    "print(\"kNN ROC-AUC on training data:\", training_roc_auc_knn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-KxRefTVRguX"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "\n",
    "plot_1 = fig.add_subplot(121,\n",
    "                       xlabel=\"FPR\", xlim=(-.01, 1.01),\n",
    "                       ylabel=\"TPR\", ylim=(-.01, 1.01), title = 'Decision Tree')\n",
    "\n",
    "# draw the first curve\n",
    "plot_1.plot(training_false_positive_rates_dt, training_true_positive_rates_dt,\n",
    "          color='darkgreen', lw=2, label = 'ROC-curve on train (AUC = %0.2f)' % training_roc_auc_dt)\n",
    "plot_1.plot(false_positive_rates_dt, true_positive_rates_dt,\n",
    "          color='darkorange', lw=2, label = 'ROC-curve on test (AUC = %0.2f)' % roc_auc_dt)\n",
    "plot_1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle=':')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# specify parameters for the second curve\n",
    "plot_2 = fig.add_subplot(122,\n",
    "                       xlabel=\"FPR\", xlim=(-.01, 1.01),\n",
    "                       ylabel=\"TPR\", ylim=(-.01, 1.01), title = 'k Nearest Neighbors')\n",
    "\n",
    "# draw the second curve\n",
    "plot_2.plot(training_false_positive_rates_knn, training_true_positive_rates_knn,\n",
    "          color='darkgreen', lw=2, label = 'ROC-curve on train (AUC = %0.2f)' % training_roc_auc_knn)\n",
    "plot_2.plot(false_positive_rates_knn, true_positive_rates_knn,\n",
    "          color='darkorange', lw=2, label = 'ROC-curve on test (AUC = %0.2f)' % roc_auc_knn)\n",
    "plot_2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle=':')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BRQnjnG4sjjR"
   },
   "source": [
    "Another ROC-AUC visualization http://www.navan.name/roc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9qr6UUHs7zb"
   },
   "source": [
    "Area under ROC-curve = probability of pairs of objects from different classes being classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "796Rlrj_ssrY"
   },
   "source": [
    "![alt text](https://alexanderdyakonov.files.wordpress.com/2017/07/eq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x5Atd7ivMIv0"
   },
   "source": [
    "$a_i$ - prediction at $i$-th object, $y_i$ - target (class), $q$- number of objects in test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I_hnBlepRguZ"
   },
   "source": [
    "## Precision and Recall\n",
    "\n",
    "Precision and Recall are two other measures for evaluation of classification quality. Both of the metrics are calculated based on **confusion matrix**.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/adasegroup/ML2024_seminars/main/seminar3/figures/precision_recall.png\">\n",
    "\n",
    "Note that Recall equals to True Positive Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isniEjqiRguZ"
   },
   "source": [
    "Although \"accuracy\" and \"precision\" have very similar meanings, they are completely different metrics. Look how Precision and Recall are evaluated for k Nearest Neighbors classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jI5lqz98Rgua"
   },
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(test_y, test_predictions_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-L5cRvxRgub"
   },
   "outputs": [],
   "source": [
    "TN, FP = confusion[0, 0], confusion[0, 1]\n",
    "FN, TP = confusion[1, 0], confusion[1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZ3xdtuPRgub"
   },
   "source": [
    "**Recall** of a classifier is equal to True Positive Rate **TPR** ($\\frac{TP}{TP + FN}$). This value may be interpreted as a sensitivity of a classifier to the objects with label `1`. If it is close to $100\\%$, then a classifier rarely \"miss\" the object of class `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_61uxNrGRguc"
   },
   "outputs": [],
   "source": [
    "recall = TP / (TP + FN)\n",
    "\n",
    "print(\"Recall: %.2f%%\" % (100 * recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3J1HymcdRgud"
   },
   "source": [
    "**Precision** -- is a fraction $\\frac{TP}{TP + FP}$. If this value is large, then a classifier assigns label `1` to objects with actual label `0` rarely.\n",
    "\n",
    "See how it is different to Accuracy = $\\frac{TP + TN}{TP + TN + FP + FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK4ZPgf0Rgud"
   },
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP)\n",
    "\n",
    "print(\"Precision: %.2f%%\" % (100 * precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tlths8-WRgue"
   },
   "source": [
    "A classifier with large Recall but small Precision produces many false positive predictions and tends to assign many `1` labels.\n",
    "\n",
    "Vice versa, if a classifier has small Recall but large Precision, then it detects class `1` accurately, but misses many objects (many false negative predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mE6H_qHoRgue"
   },
   "source": [
    "### Precision-Recall curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cgp4cveRguf"
   },
   "source": [
    "In **precision-recall** space we may construct a curve similar to **ROC** curve in **FPR-TPR** space. PR curve also depicts the dependecy of Precision and Recall on threshold. *scikit* has the corresponding function: **precision_recall_curve(...)**.\n",
    "\n",
    "Let's calculate PR curve points.\n",
    "\n",
    "Note that unlike ROC curve, we cannot use interpolation for calculation of area under the curve. This may lead to larger values of the metric, which is not good. In this case we need to use **average_precision_score()** function instead of **auc()** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEIzrTmiRguf"
   },
   "outputs": [],
   "source": [
    "# generate values for Precision-Recall curve\n",
    "precision_dt, recall_dt, _ = precision_recall_curve(test_y, test_probabilities_dt)\n",
    "precision_knn, recall_knn, _ = precision_recall_curve(test_y, test_probabilities_knn)\n",
    "\n",
    "# calculate value under Precision-Recall curve\n",
    "pr_auc_dt = average_precision_score(test_y, test_probabilities_dt)\n",
    "pr_auc_knn = average_precision_score(test_y, test_probabilities_knn)\n",
    "\n",
    "print(\"DT PR-AUC on test data:\", pr_auc_dt) \n",
    "print(\"kNN PR-AUC on test data:\", pr_auc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymsau0J_Rgug"
   },
   "outputs": [],
   "source": [
    "# generate values for training Precision Recall curve\n",
    "training_precision_dt, training_recall_dt, _ = precision_recall_curve(training_y, training_probabilities_dt)\n",
    "training_precision_knn, training_recall_knn, _ = precision_recall_curve(training_y, training_probabilities_knn)\n",
    "\n",
    "# TODO calculate value under precision-recall curve\n",
    "training_pr_auc_dt = average_precision_score(training_y, training_probabilities_dt)\n",
    "training_pr_auc_knn = average_precision_score(training_y, training_probabilities_knn)\n",
    "\n",
    "print(\"DT PR-AUC on training data:\", training_pr_auc_dt) \n",
    "print(\"kNN PR-AUC on training data:\", training_pr_auc_knn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GflTFHKgRguh"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "\n",
    "plot_1 = fig.add_subplot(121,\n",
    "                       xlabel=\"Recall\", xlim=(-.01, 1.01),\n",
    "                       ylabel=\"Precision\", ylim=(-.01, 1.01), title = 'Decision Tree')\n",
    "\n",
    "plot_1.plot(training_recall_dt, training_precision_dt,\n",
    "          color='darkgreen', lw=2, label = 'PR-curve on train (AUC = %0.2f)' % training_pr_auc_dt)\n",
    "plot_1.plot(recall_dt, precision_dt,\n",
    "          color='darkorange', lw=2, label = 'PR-curve on test (AUC = %0.2f)' % pr_auc_dt)\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "plot_2 = fig.add_subplot(122,\n",
    "                       xlabel=\"Recall\", xlim=(-.01, 1.01),\n",
    "                       ylabel=\"Precision\", ylim=(-.01, 1.01), title = 'k Nearest Neighbors')\n",
    "\n",
    "plot_2.plot(training_recall_knn, training_precision_knn,\n",
    "          color='darkgreen', lw=2, label = 'PR-curve on train (AUC = %0.2f)' % training_pr_auc_knn)\n",
    "plot_2.plot(recall_knn, precision_knn,\n",
    "          color='darkorange', lw=2, label = 'PR-curve on test (AUC = %0.2f)' % pr_auc_knn)\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1M5pctyRgui"
   },
   "source": [
    "The closer **PR** curve to the **upper right** corner, the better classification is.\n",
    "\n",
    "Large AUC value means that Precision and Recall are also large. That means that classifier makes small number of both False Positives and False Negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d2yCJoE1Rgui"
   },
   "source": [
    "## F1 score\n",
    "\n",
    "This metric allows to take into account a different cost for False Positive Errors and False Negative Errors.\n",
    "\n",
    "General $F_\\beta$ score is defined as follows:\n",
    "$$\n",
    "F_\\beta = (1 + \\beta^2) \\frac{Precision \\cdot Recall}{\\beta^2 Precision + Recall} = \\frac{1 + \\beta^2}{\\frac{\\beta^2}{Recall} + \\frac{1}{Precision}}= \\frac{\\beta + \\beta^{-1}}{\\beta\\frac{1}{\\text{Recall}} + \\beta^{-1}\\frac{1}{\\text{Precision}}}\n",
    "    \\,.\n",
    "$$\n",
    "\n",
    "Most commonly used is $F_1$ score:\n",
    "$$\n",
    "F_1 = 2 \\frac{Precision \\cdot Recall}{Precision + Recall}\n",
    "$$\n",
    "\n",
    "Harmonic mean is used in order to make metric value very small when Precision or Recall is close to zero. Note that $F_1$ score doesn't describe how classifier works for True Negative results (**TN**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7QtQhePRgui"
   },
   "outputs": [],
   "source": [
    "print(\"DT F1 score on training data\", f1_score(training_y, training_predictions_dt))\n",
    "print(\"kNN F1 score on training data\", f1_score(training_y, training_predictions_knn))\n",
    "\n",
    "print(\"DT F1 score on test data\", f1_score(test_y, test_predictions_dt))\n",
    "print(\"kNN F1 score on test data\", f1_score(test_y, test_predictions_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUI4RS4iRguj"
   },
   "source": [
    "$F_1$ score is good for imbalanced classification, when a number of class `1` objects is **much** bigger than class `0` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsvimD8oRguj"
   },
   "source": [
    "Let's compare **accuracy** and $F_1$ score of our classifiers with *random* classifier, which works as follows:\n",
    "\n",
    "* estimate probability $\\hat{p}$ of class `1` on training data (frequency of class `1` objects);\n",
    "* for every test object predict randomly:\n",
    "    * label `1` with probability $\\hat{p}$,\n",
    "    * label `0` with probability $1 - \\hat{p}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N6jrY5vkRguk"
   },
   "outputs": [],
   "source": [
    "training_prob = sum(training_y) / len(training_y)\n",
    "random_predictions = np.random.binomial(1, training_prob, len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSnRWleIRguk"
   },
   "outputs": [],
   "source": [
    "print(\"Decision Tree accuracy\\t\\t\", accuracy_score(test_y, test_predictions_dt))\n",
    "print(\"kNN accuracy\\t\\t\\t\", accuracy_score(test_y, test_predictions_knn))\n",
    "print(\"Random classifier accuracy\\t\", accuracy_score(test_y, random_predictions))\n",
    "print('---')\n",
    "print(\"Decision Tree F1 score\\t\\t\", f1_score(test_y, test_predictions_dt))\n",
    "print(\"kNN F1 score\\t\\t\\t\", f1_score(test_y, test_predictions_knn))\n",
    "print(\"FRandom classifier F1 score\\t\", f1_score(test_y, random_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR-2x26HRgul"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "We have seen how some of classifiers work for this dataset. Now, try it yourself with Logistic Regression.\n",
    "\n",
    "* Fisrt, **import** **LogisticRegression()** function and train it on training data.\n",
    "* Then, calculate **ROC AUC**, **PR AUC** and **F1 score** on test data.\n",
    "* Try to change parameters to improve results.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohvRKx9ORgul"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6TkioS4Rguo"
   },
   "source": [
    "# Cross-validation technique\n",
    "\n",
    "In many cases test sample is not available or we have a small dataset, and we have only one sample: a training one. The most popular approach in this case is **cross-validation**.\n",
    "\n",
    "The most common way is $k$-fold cross-validation. The idea is to divide training sample into $k$ blocks, one of them is treated as an artificial test sample and other $k-1$ are used for training.\n",
    "\n",
    "*scikit* has several functions for dividing data into folds and for performing automated cross-validation. One of those functions is **GridSearchCV()**.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/adasegroup/ML2024_seminars/main/seminar3/figures/5-fold-cv.png?raw=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYrK5jMjRguo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyEK6VfhRgup"
   },
   "outputs": [],
   "source": [
    "parameters_knn = {'n_neighbors': [5, 10, 15, 20]}\n",
    "knn_cv = GridSearchCV(knn, param_grid = parameters_knn)\n",
    "knn_cv.fit(training_X, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2Sx0OsQd7Bo"
   },
   "outputs": [],
   "source": [
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UsU_RBGXRgus"
   },
   "outputs": [],
   "source": [
    "predictions_knn_cv = knn_cv.predict(test_X)\n",
    "probabilities_knn_cv = knn_cv.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCaJEBADRgus"
   },
   "outputs": [],
   "source": [
    "false_positive_rates_knn_cv, true_positive_rates_knn_cv, _ = roc_curve(test_y, probabilities_knn_cv)\n",
    "roc_auc_knn_cv = auc(false_positive_rates_knn_cv, true_positive_rates_knn_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_O13F2iRgut"
   },
   "outputs": [],
   "source": [
    "precision_knn_cv, recall_knn_cv, _ = precision_recall_curve(test_y, probabilities_knn_cv)\n",
    "pr_auc_knn_cv = average_precision_score(test_y, probabilities_knn_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JqCy0TkRguu"
   },
   "outputs": [],
   "source": [
    "f1_knn_cv = f1_score(test_y, predictions_knn_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WBayVmzeayJY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NZmrRQeRguv"
   },
   "outputs": [],
   "source": [
    "print('ROC AUC: ', roc_auc_knn_cv)\n",
    "print('PR AUC: ', pr_auc_knn_cv)\n",
    "print('F1_score: ', f1_knn_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkOJbuP3Rguv"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(test_y, predictions_knn_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ecCmIdSRguw"
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Now we know how to perform cross-validation. Try it yourself with Decision Tree.\n",
    "\n",
    "* Using **GridSearchCV** choose parameter **min_samples_leaf**. Try several values from 1 to 100.\n",
    "* Use **five**-fold cross-validation and **roc_auc** scoring. See the chosen parameters.\n",
    "* Evaluate quality metrics and look how they changed. Try to make some plots.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "HINT https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raCbonaXRguz"
   },
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnMA4V91Rguz"
   },
   "source": [
    "Let's have a look how multiclass tasks are treated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgxZfcduRguz"
   },
   "outputs": [],
   "source": [
    "# import some modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYuYzhKPRgu0"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Ky3MohKRgu1"
   },
   "source": [
    "We will use data from Kaggle contest *\"Otto Group\n",
    "Product Classification Challenge\"*, which was created to predict class of an item by several features.\n",
    "\n",
    "https://www.kaggle.com/c/otto-group-product-classification-challenge\n",
    "\n",
    "Data are in ZIP, but we can load them easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFnNfzLoRgu1"
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('https://raw.githubusercontent.com/adasegroup/ML2024_seminars/master/seminar3/otto/train.csv', index_col='id')\n",
    "test_dataset = pd.read_csv('https://raw.githubusercontent.com/adasegroup/ML2024_seminars/master/seminar3/otto/test.cutted.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPqHmPCxRgu1"
   },
   "source": [
    "Data consist of the following:\n",
    "* **id** -- anonymized identifier;\n",
    "* **feat_1, ..., feat_93** -- features;\n",
    "* **target** -- actual class of an item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ueVKaFb4Rgu1"
   },
   "source": [
    "Number of objects for every class in **target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2EcbhnoRgu1"
   },
   "outputs": [],
   "source": [
    "train_dataset['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2r5agzoexIVe"
   },
   "outputs": [],
   "source": [
    "y = train_dataset[\"target\"]\n",
    "X = np.asarray(train_dataset.drop(\"target\", axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_oPMs0iRgu2"
   },
   "source": [
    "Let's see data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wOgXzk8Rgu2"
   },
   "outputs": [],
   "source": [
    "train_dataset.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgyHdvdFRgu3"
   },
   "source": [
    "Divide data into input and output, transform labels from strings to numbers. **LabelEncoder** allows us to perform that transform nad obtain numbers from $0$ to $K-1$, where $K$ is the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXjtlHH7wmXT"
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ucBjN3-wrmd"
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(objective='multi:softprob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ifeaZF1wGql"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KysEGAkRgu3"
   },
   "source": [
    "Split data into training sample and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWEn1KRGRgu4"
   },
   "outputs": [],
   "source": [
    "split = train_test_split(X, y, test_size=0.5,\n",
    "                         random_state=42, stratify=y)\n",
    "train_X, test_X, train_y, test_y = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qH2WZtDqyOUi"
   },
   "outputs": [],
   "source": [
    "xgb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BspFML4ky0-q"
   },
   "outputs": [],
   "source": [
    "test_preds = xgb.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JB5hnvsby4ue"
   },
   "outputs": [],
   "source": [
    "accuracy_score(test_y, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UckCZ9X-y6Cq"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(test_y, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPzYZscA1FHI"
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_y, test_preds))"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 36,
  "_is_fork": false,
  "colab": {
   "name": "Seminar_3.ipynb",
   "provenance": []
  },
  "include_colab_link": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
